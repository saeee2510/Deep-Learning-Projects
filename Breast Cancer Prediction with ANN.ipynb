{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "175c0f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a6ea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data (1).csv\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "del df['Unnamed: 32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ad95b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  fractal_dimension_mean  radius_se  texture_se  perimeter_se  \\\n",
       "0         0.2419                 0.07871     1.0950      0.9053         8.589   \n",
       "1         0.1812                 0.05667     0.5435      0.7339         3.398   \n",
       "2         0.2069                 0.05999     0.7456      0.7869         4.585   \n",
       "3         0.2597                 0.09744     0.4956      1.1560         3.445   \n",
       "4         0.1809                 0.05883     0.7572      0.7813         5.438   \n",
       "\n",
       "   area_se  smoothness_se  compactness_se  concavity_se  concave points_se  \\\n",
       "0   153.40       0.006399         0.04904       0.05373            0.01587   \n",
       "1    74.08       0.005225         0.01308       0.01860            0.01340   \n",
       "2    94.03       0.006150         0.04006       0.03832            0.02058   \n",
       "3    27.23       0.009110         0.07458       0.05661            0.01867   \n",
       "4    94.44       0.011490         0.02461       0.05688            0.01885   \n",
       "\n",
       "   symmetry_se  fractal_dimension_se  radius_worst  texture_worst  \\\n",
       "0      0.03003              0.006193         25.38          17.33   \n",
       "1      0.01389              0.003532         24.99          23.41   \n",
       "2      0.02250              0.004571         23.57          25.53   \n",
       "3      0.05963              0.009208         14.91          26.50   \n",
       "4      0.01756              0.005115         22.54          16.67   \n",
       "\n",
       "   perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0           184.60      2019.0            0.1622             0.6656   \n",
       "1           158.80      1956.0            0.1238             0.1866   \n",
       "2           152.50      1709.0            0.1444             0.4245   \n",
       "3            98.87       567.7            0.2098             0.8663   \n",
       "4           152.20      1575.0            0.1374             0.2050   \n",
       "\n",
       "   concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0           0.7119                0.2654          0.4601   \n",
       "1           0.2416                0.1860          0.2750   \n",
       "2           0.4504                0.2430          0.3613   \n",
       "3           0.6869                0.2575          0.6638   \n",
       "4           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "2                  0.08758  \n",
       "3                  0.17300  \n",
       "4                  0.07678  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c072594",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,2:].values\n",
    "y = df.iloc[:,1].values\n",
    "\n",
    "## Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "y = labelencoder_X_1.fit_transform(y)\n",
    "\n",
    "## splitting the dataset into train set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.1, random_state = 0)\n",
    "\n",
    "\n",
    "## feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c67e9f9",
   "metadata": {},
   "source": [
    "### Now that we have prepared data, we will import Keras and its packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28d43941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "817ad21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initializing the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca748814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(16, kernel_initializer='uniform', activation='relu', input_dim=30))\n",
    "# Adding dropout to prevent overfitting\n",
    "classifier.add(Dropout(rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69f06bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding the second hidden layer\n",
    "classifier.add(Dense(16,kernel_initializer='uniform',activation='relu'))\n",
    "# Adding dropout to prevent overfitting\n",
    "classifier.add(Dropout(rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fae97a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding the output layer\n",
    "classifier.add(Dense(1,kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5aa96490",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d28961fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5547 - loss: 0.6929  \n",
      "Epoch 2/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6087 - loss: 0.6920 \n",
      "Epoch 3/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.6275 - loss: 0.6906\n",
      "Epoch 4/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 0.6365 - loss: 0.6885\n",
      "Epoch 5/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.6348 - loss: 0.6853\n",
      "Epoch 6/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.6195 - loss: 0.6808\n",
      "Epoch 7/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.6605 - loss: 0.6721\n",
      "Epoch 8/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.7179 - loss: 0.6602\n",
      "Epoch 9/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8042 - loss: 0.6443 \n",
      "Epoch 10/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 0.9050 - loss: 0.6169\n",
      "Epoch 11/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 0.9453 - loss: 0.5789\n",
      "Epoch 12/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.9567 - loss: 0.5283\n",
      "Epoch 13/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.9535 - loss: 0.4614\n",
      "Epoch 14/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9529 - loss: 0.3944 \n",
      "Epoch 15/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9523 - loss: 0.3289 \n",
      "Epoch 16/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 0.9495 - loss: 0.2679\n",
      "Epoch 17/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.9652 - loss: 0.2098\n",
      "Epoch 18/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.9644 - loss: 0.1774\n",
      "Epoch 19/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.9702 - loss: 0.1388\n",
      "Epoch 20/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.9638 - loss: 0.1460\n",
      "Epoch 21/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.9709 - loss: 0.1120\n",
      "Epoch 22/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.9729 - loss: 0.1132\n",
      "Epoch 23/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.9695 - loss: 0.1115\n",
      "Epoch 24/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.9776 - loss: 0.0922\n",
      "Epoch 25/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9841 - loss: 0.0762 \n",
      "Epoch 26/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.9752 - loss: 0.0832\n",
      "Epoch 27/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.9820 - loss: 0.0727\n",
      "Epoch 28/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.9803 - loss: 0.0785\n",
      "Epoch 29/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.9853 - loss: 0.0714\n",
      "Epoch 30/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.9828 - loss: 0.0766\n",
      "Epoch 31/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.9818 - loss: 0.0716\n",
      "Epoch 32/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.9786 - loss: 0.0775\n",
      "Epoch 33/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.9863 - loss: 0.0707\n",
      "Epoch 34/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.9844 - loss: 0.0604\n",
      "Epoch 35/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.9790 - loss: 0.0873\n",
      "Epoch 36/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.9834 - loss: 0.0628\n",
      "Epoch 37/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.9817 - loss: 0.0665\n",
      "Epoch 38/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.9831 - loss: 0.0625\n",
      "Epoch 39/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.9844 - loss: 0.0637\n",
      "Epoch 40/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.9842 - loss: 0.0678\n",
      "Epoch 41/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.9881 - loss: 0.0514\n",
      "Epoch 42/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.9853 - loss: 0.0610\n",
      "Epoch 43/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9881 - loss: 0.0536 \n",
      "Epoch 44/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.9920 - loss: 0.0584\n",
      "Epoch 45/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.9871 - loss: 0.0593\n",
      "Epoch 46/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.9871 - loss: 0.0598\n",
      "Epoch 47/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.9858 - loss: 0.0681\n",
      "Epoch 48/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - accuracy: 0.9868 - loss: 0.0593\n",
      "Epoch 49/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.9867 - loss: 0.0616\n",
      "Epoch 50/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9914 - loss: 0.0453 \n",
      "Epoch 51/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.9854 - loss: 0.0719\n",
      "Epoch 52/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.9846 - loss: 0.0637\n",
      "Epoch 53/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.9867 - loss: 0.0514\n",
      "Epoch 54/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.9872 - loss: 0.0460\n",
      "Epoch 55/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.9847 - loss: 0.0694\n",
      "Epoch 56/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.9860 - loss: 0.0540\n",
      "Epoch 57/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.9850 - loss: 0.0567\n",
      "Epoch 58/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.9810 - loss: 0.0670\n",
      "Epoch 59/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.9852 - loss: 0.0589\n",
      "Epoch 60/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.9797 - loss: 0.0574\n",
      "Epoch 61/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.9836 - loss: 0.0599\n",
      "Epoch 62/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.9877 - loss: 0.0480\n",
      "Epoch 63/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.9847 - loss: 0.0624\n",
      "Epoch 64/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.9870 - loss: 0.0478\n",
      "Epoch 65/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.9917 - loss: 0.0332\n",
      "Epoch 66/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.9861 - loss: 0.0553\n",
      "Epoch 67/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.9896 - loss: 0.0378\n",
      "Epoch 68/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.9893 - loss: 0.0404\n",
      "Epoch 69/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.9871 - loss: 0.0507\n",
      "Epoch 70/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9850 - loss: 0.0674 \n",
      "Epoch 71/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.9864 - loss: 0.0547\n",
      "Epoch 72/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.9849 - loss: 0.0580\n",
      "Epoch 73/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.9910 - loss: 0.0391\n",
      "Epoch 74/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.9895 - loss: 0.0510\n",
      "Epoch 75/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.9910 - loss: 0.0337\n",
      "Epoch 76/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.9913 - loss: 0.0444\n",
      "Epoch 77/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.9932 - loss: 0.0418\n",
      "Epoch 78/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.9907 - loss: 0.0460\n",
      "Epoch 79/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.9904 - loss: 0.0418\n",
      "Epoch 80/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.9915 - loss: 0.0456\n",
      "Epoch 81/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.9928 - loss: 0.0424\n",
      "Epoch 82/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.9919 - loss: 0.0359\n",
      "Epoch 83/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.9879 - loss: 0.0424\n",
      "Epoch 84/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.9931 - loss: 0.0436\n",
      "Epoch 85/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.9860 - loss: 0.0609\n",
      "Epoch 86/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.9936 - loss: 0.0347\n",
      "Epoch 87/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.9946 - loss: 0.0311\n",
      "Epoch 88/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.9921 - loss: 0.0375\n",
      "Epoch 89/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.9927 - loss: 0.0379\n",
      "Epoch 90/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.9909 - loss: 0.0377\n",
      "Epoch 91/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.9939 - loss: 0.0306\n",
      "Epoch 92/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.9911 - loss: 0.0388\n",
      "Epoch 93/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.9900 - loss: 0.0516\n",
      "Epoch 94/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 0.9906 - loss: 0.0419\n",
      "Epoch 95/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - accuracy: 0.9951 - loss: 0.0285\n",
      "Epoch 96/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.9909 - loss: 0.0459\n",
      "Epoch 97/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.9904 - loss: 0.0385\n",
      "Epoch 98/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.9921 - loss: 0.0419\n",
      "Epoch 99/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.9925 - loss: 0.0353\n",
      "Epoch 100/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.9877 - loss: 0.0492\n",
      "Epoch 101/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9946 - loss: 0.0254 \n",
      "Epoch 102/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.9906 - loss: 0.0445\n",
      "Epoch 103/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.9895 - loss: 0.0402\n",
      "Epoch 104/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.9947 - loss: 0.0242\n",
      "Epoch 105/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.9947 - loss: 0.0277\n",
      "Epoch 106/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.9940 - loss: 0.0292\n",
      "Epoch 107/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - accuracy: 0.9909 - loss: 0.0424\n",
      "Epoch 108/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.9891 - loss: 0.0486\n",
      "Epoch 109/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.9941 - loss: 0.0286\n",
      "Epoch 110/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.9929 - loss: 0.0306\n",
      "Epoch 111/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.9954 - loss: 0.0211\n",
      "Epoch 112/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.9969 - loss: 0.0326\n",
      "Epoch 113/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.9939 - loss: 0.0286\n",
      "Epoch 114/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.9928 - loss: 0.0281\n",
      "Epoch 115/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.9883 - loss: 0.0446\n",
      "Epoch 116/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.9935 - loss: 0.0268\n",
      "Epoch 117/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.9888 - loss: 0.0452\n",
      "Epoch 118/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.9925 - loss: 0.0290\n",
      "Epoch 119/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.9913 - loss: 0.0368\n",
      "Epoch 120/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.9927 - loss: 0.0337\n",
      "Epoch 121/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.9933 - loss: 0.0277\n",
      "Epoch 122/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.9936 - loss: 0.0350\n",
      "Epoch 123/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.9961 - loss: 0.0358\n",
      "Epoch 124/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.9898 - loss: 0.0421\n",
      "Epoch 125/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.9944 - loss: 0.0226\n",
      "Epoch 126/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.9920 - loss: 0.0330\n",
      "Epoch 127/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.9873 - loss: 0.0429\n",
      "Epoch 128/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.9911 - loss: 0.0327\n",
      "Epoch 129/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9933 - loss: 0.0271 \n",
      "Epoch 130/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.9883 - loss: 0.0385\n",
      "Epoch 131/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.9957 - loss: 0.0275\n",
      "Epoch 132/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.9906 - loss: 0.0329\n",
      "Epoch 133/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.9963 - loss: 0.0242\n",
      "Epoch 134/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9925 - loss: 0.0314 \n",
      "Epoch 135/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.9966 - loss: 0.0197\n",
      "Epoch 136/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9938 - loss: 0.0288 \n",
      "Epoch 137/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.9927 - loss: 0.0242\n",
      "Epoch 138/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.9944 - loss: 0.0182\n",
      "Epoch 139/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.9946 - loss: 0.0223\n",
      "Epoch 140/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.9945 - loss: 0.0274\n",
      "Epoch 141/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.9909 - loss: 0.0292\n",
      "Epoch 142/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.9898 - loss: 0.0297\n",
      "Epoch 143/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.9917 - loss: 0.0209\n",
      "Epoch 144/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.9890 - loss: 0.0300\n",
      "Epoch 145/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.9944 - loss: 0.0217\n",
      "Epoch 146/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.9890 - loss: 0.0364\n",
      "Epoch 147/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.9963 - loss: 0.0188\n",
      "Epoch 148/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.9947 - loss: 0.0206\n",
      "Epoch 149/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.9897 - loss: 0.0328\n",
      "Epoch 150/150\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.9928 - loss: 0.0269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1790098d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fitting the ANN to the training set\n",
    "classifier.fit(X_train, y_train, batch_size=100, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4c5c2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    }
   ],
   "source": [
    "## Predicting the test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8c6584b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77d579dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our accuracy is 94.73684210526315%\n"
     ]
    }
   ],
   "source": [
    "print(\"Our accuracy is {}%\".format(((cm[0][0] + cm[1][1])/57)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7a106d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm,annot=True)\n",
    "plt.savefig('h.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
